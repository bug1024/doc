# 常见集合类实现原理
* TreeSet和HashSet去重原理
    * TreeSet去重原理：compareTo
    * HashSet去重原理：hascode equals
* HashMap实现原理，HashMap扩容以及HashMap多线程下发生死循环的原因
* Hashtable与HashMap比较
    * HashTable 基于 Dictionary 类，而 HashMap 是基于 AbstractMap。Dictionary 是任何可将键映射到相应值的类的抽象父类，而 AbstractMap 是基于 Map 接口的实现，它以最大限度地减少实现此接口所需的工作。
    * HashMap 的 key 和 value 都允许为 null，而 Hashtable 的 key 和 value 都不允许为 null。
    * Hashtable 方法是同步，而HashMap则不是。Hashtable中的几乎所有的public方法都是synchronized 
* ConcurrentHashMap的实现原理，JDK8的实现跟JDK7有什么不同
    * 锁分段技术
    * Segment是一种可重入锁ReentrantLock
    * get操作不加锁的的原因是它的get方法里将要使用的共享变量都定义成volatile
    * JDK8中，ConcurrentHashMap不再使用Segment分离锁，而是采用一种乐观锁CAS算法来实现同步问题，但其底层还是“数组+链表->红黑树”的实现
* TreeMap和LinkedHashMap是如何保证有序
    * TreeMap数据是有序的，底层是一个红黑树
    * LinkedHashMap他是hashMap的一个子类，底层维护了一个双向链表，他可以实现输入的顺序和输出的顺序相同
    * LinkedHashMap 几乎和 HashMap 一样：从技术上来说，不同的是它定义了一个 Entry<K,V> header，这个 header 不是放在 Table 里，它是额外独立出来的。LinkedHashMap 通过继承 hashMap 中的 Entry<K,V>,并添加两个属性 Entry<K,V> before,after,和 header 结合起来组成一个双向链表，来实现按插入顺序或访问顺序排序。
* ArrayList是线程安全的吗?Vector呢？
    * Vector使用synchronized实现同步
* ArrayListCopyOnWriteArrayList是如何实现线程安全的
    * 读操作是无锁的，性能较高。至于写操作，比如向容器中添加一个元素，则首先将当前容器复制一份，然后在新副本上执行写操作，结束之后再将原容器的引用指向新容器。

# 类加载器原理
* 类加载主要步骤
    * 加载 验证 准备 解析 初始化
* 类加载器都有哪些
    * 启动类加载器 扩展类加载器 应用程序加载器 自定义加载器
* 什么是双亲委派模型，为什么要使用
    * 类加载器收到类加载任务，会先交给其父类加载器去完成，因此最终加载任务都会传递到顶层的启动类加载器，只有当父类加载器无法完成加载任务时，才会尝试执行加载任务
    * 主要是安全性考虑，害怕用户自己定义class文件然后自己写一个类加载器来加载原本应该是JVM自己加载的类
    * 保证了使用不同的类加载器最终得到的都是同样一个对象
* 如何自定义类加载器，自己的类加载器和Java自带的类加载器关系如何处理
    * ClassLoader加载类的顺序
        * 调用findLoadedClass(String) 来检查是否已经加载类
        * 在父类加载器上调用loadClass方法。如果父亲不能加载，一次一级一级传给子类
        * 调用子类findClass(String) 方法查找类。若还加载不了就返回ClassNotFoundException，不交给发起请求的加载器的子加载器
    * 实现自己的类加载器
        * 获取类的class文件的字节数组，如loadClassData方法
        * 将字节数组转换为Class类的实例，重写findClass中调用的defineClass方法
* 包冲突，类冲突的形成原理及解决办法（可能会引申JDK9的模块化设计）
    * Java应用程序因某种因素，加载不到正确的类而导致其行为跟预期不一致
    * Maven的仲裁机制
    * JDK9模块化：package之上的包装，意味着public方法不再任意可访问
* class.forName("java.lang.String")和String.class.getClassLoader.loadClass("java.lang.String")区别？
    * Class.forName是从指定的classloader中装载类,如果没有指定,也就是一个参数的时候,是从装载当前对象实例所在的classloader中装载类
    * ClassLoader的实例调用loadclass方法,是指从当前ClassLoader实例中调用类,而这个实例与装载当前所在类实例的Classloader也许不是同一个
    * 说白了就是他们实现装载的时候，使用的类装载器的指定是不同的

# 线程和并发
* 什么是daemon线程
    * 守护线程，是指在程序运行的时候在后台提供一种通用服务的线程
    * 当所有的非守护线程结束时，程序也就终止了，同时会杀死进程中的所有守护线程
    * thread.setDaemon(true)必须在thread.start()之前设置，否则会跑出一个IllegalThreadStateException异常。你不能把正在运行的常规线程设置为守护线程
    * 在Daemon线程中产生的新线程也是Daemon的
    * 守护线程应该永远不去访问固有资源，如文件、数据库，因为它会在任何时候甚至在一个操作的中间发生中断
* 什么是线程安全
    * 线程安全是指多线程操作同一个对象结果都一致不会出现问题
* 如果有多个线程要并发操作一个文件，如何做到线程安全，请写出伪代码
* syncronized/volatile关键字
    * 粒度不同，前者针对变量 ，后者锁对象和类
    * sync阻塞，volatile线程不阻塞
    * sync保证三大特性，volatile不保证原子性
    * sync编译器优化，volatile不优化 volatile具备两种特性：
* sleep方法和wait方法有什么区别
    * sleep保持对象锁，仍然占有该锁，而wait会释放对象锁
* 悲观锁和乐观锁的区别
    * 悲观锁：每次都加锁，适合写入操作比较频繁的场景
    * 乐观锁：更新数据的时候需要判断该数据是否被别人修改过。如果数据被其他线程修改，则不进行数据更新，比较适合读取频繁的场景
* 有哪些并发模型，用过哪些并发模型，选择这些模型有什么依据(比如说Master-Worker模式)
* 用过ThreadLocal吗?什么场景下用过
    * 每个ThreadLocal可以放一个线程级别的变量，但是它本身可以被多个线程共享使用，而且又可以达到线程安全的目的
，  * 更准确的说是为了实现线程间的数据隔离
    * 使用场景：某个方法处理一个业务，需要递归依赖其他方法时，而要在这些方法中共享参数的问题
    * 所使用的ThreadLocal变量的实际数据，通过get函数取值的时候，就是通过取出Thread中threadLocals引用的map，然后从这个map中根据当前threadLocal作为参数，取出数据
    * ThreadLocalMap实现和HashMap差不多，但是在hash冲突的处理上有区别。 ThreadLocalMap中发生hash冲突时，不是像HashMap这样用链表来解决冲突，而是是将索引++，放到下一个索引处来解决冲突
* 线程有哪几种状态
    * 创建 就绪 运行 阻塞 死亡
* blocked和wait区别
    * BLOCKED是指线程正在等待获取锁；
    * WAITING是指线程正在等待其他线程发来的通知（notify）
* 线程池实现原理，创建线程池的几个参数的含义
    * corePoolSize：核心池的大小，在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，在没有任务到来之前就创建corePoolSize个线程或者一个线程。默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中；
    * maximumPoolSize：线程池最大线程数，它表示在线程池中最多能创建多少个线程
    * keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止
    * unit：参数keepAliveTime的时间单位，有7种取值
    * workQueue：一个阻塞队列，用来存储等待执行的任务
    * threadFactory：线程工厂，主要用来创建线程
    * handler：表示当拒绝处理任务时的策略
* 常见线程池
    * newSingleThreadExecutor 单个线程的线程池，即线程池中每次只有一个线程工作，单线程串行执行任务
    * newFixedThreadExecutor(n) 固定数量的线程池，没提交一个任务就是一个线程，直到达到线程池的最大数量，然后后面进入等待队列直到前面的任务完成才继续执行
    * newCacheThreadExecutor（推荐使用）可缓存线程池，当线程池大小超过了处理任务所需的线程，那么就会回收部分空闲（一般是60秒无执行）的线程，当有任务来时，又智能的添加新线程来执行。
    * newScheduleThreadExecutor 大小无限制的线程池，支持定时和周期性的执行线程
* 多线程最佳实践
    * 给你的线程起个有意义的名字
    * 避免锁定和缩小同步的范围
    * 多用并发集合少用同步集合
    * 多用同步类少用wait 和 notify
* Thread 类中的start() 和 run() 方法有什么区别
    * start()方法被用来启动新创建的线程，而且start()内部调用了run()方法，这和直接调用run()方法的效果不一样
    * run()方法的时候，只会是在原来的线程中调用，没有新的线程启动，start()方法才会启动新线程
* Java中Runnable和Callable有什么不同？
    * Runnable和Callable都代表那些要在不同的线程中执行的任务。
    * Runnable从JDK1.0开始就有了，Callable是在JDK1.5增加的。
    * Callable的 call() 方法可以返回值和抛出异常，而Runnable的run()方法没有这些功能。Callable可以返回装载有计算结果的Future对象
* Thread类中的yield方法有什么作用？
    * Yield方法可以暂停当前正在执行的线程对象，让其它有相同优先级的线程执行。它是一个静态方法而且只保证当前线程放弃CPU占用而不能保证使其它线程一定能占用CPU，执行yield()的线程有可能在进入到暂停状态后马上又被执行
* 工作中遇到的高并发场景与问题

# 锁
* 写一个发生死锁的JAVA代码，并描述一下如何避免死锁
    * 加锁顺序
    * 加锁时限
    * 死锁检测
* CAS概念
    * Compare And Swap CAS是乐观锁技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。
    * CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。
* 线程要进入阻塞状态，操作系统是如何操作的(涉及到用户态和内核态)
* 谈谈如何进行锁的优化
    * 减少锁持有时间
    * 减小锁粒度
    * 锁分离 最常见的锁分离就是读写锁ReadWriteLock
    * JVM层面 偏向锁 轻量级锁 自旋锁
* 什么叫可重入锁
    * 也叫做递归锁，指的是同一线程外层函数获得锁之后，内层递归函数仍然有获取该锁的代码，但不受影响。在JAVA环境下ReentrantLock和synchronized都是可重入锁
    * 最大的作用是避免死锁
* 比较ReentrantLock和synchronized
    * synchronized获得的内部锁存在一定的局限:
    * 不能中断一个正在试图获得锁的线程
    * 试图获得锁时不能像trylock那样设定超时时间
    * 每个锁只有单一的条件，不像condition那样可以设置多个
* 如何查看死锁情况
    * jstack -l

# JVM
* JVM垃圾回收算法有哪几种？各种有什么特点
* 什么时候触发young gc，什么时候触发full
    * young gc：当young gen中的eden区分配满的时候触发。注意young GC中有部分存活对象会晋升到old gen，所以young GC后old gen的占用量通常会有所升高。
    * full gc：
        * 当准备要触发一次young GC时，如果发现统计数据说之前young GC的平均晋升大小比目前old gen剩余的空间大，则不会触发young GC而是转为触发full GC
        * 如果有perm gen的话，要在perm gen分配空间但已经没有足够空间时，也要触发一次full GC
        * System.gc()、heap dump带GC，默认也是触发full GC
* 如果JAVA进程突然挂掉了，怎么查看挂掉的原因
    * java进程挂掉后，会产生core dump文件，可以使用jstack命令输出线程堆栈信息
* 线上频繁full gc如何处理？cpu使用率过高怎么办？如何定位问题？如何解决？思路和方法怎样的？
    * full gc频繁说明old区很快满了
    * 如果是一次fullgc后，剩余对象不多。那么说明你eden区设置太小，导致短生命周期的对象进入了old区
    * 如果一次fullgc后，old区回收率不大，那么说明old区太小
* JVM监控工具有哪些，各有什么用途，简单介绍一下用法
    * jps
    * jstat
    * jmap
    * jstack
    * Java VisualVM
* 描述一下JVM的内存模型
    * 程序计数器
    * Java虚拟机栈
    * 本地方法栈
    * 堆
    * 方法区
* 简述java内存分配与回收策率以及Minor GC和Major GC
    * 对象优先在堆的Eden区分配
    * 大对象直接进入老年代
    * 长期存活的对象将直接进入老年代
    * 当Eden区没有足够的空间进行分配时，虚拟机会执行一次Minor GC.Minor Gc通常发生在新生代的Eden区，在这个区的对象生存期短，往往发生Gc的频率较高，回收速度比较快;Full Gc/Major GC 发生在老年代，一般情况下，触发老年代GC的时候不会触发Minor GC,但是通过配置，可以在Full GC之前进行一次Minor GC这样可以加快老年代的回收速度
* GC收集算法
    * 标记清除 从根节点开始标记所有可达对象，其余没有标记的即为垃圾对象，执行清除。但回收后的空间是不连续的
    * 标记整理 采用标记清除算法一样的方式进行对象的标记，但在清除时，在回收不存活的对象占用的空间后，会将所有的存活对象网左端空闲空间移动，并更新相应的指针，进行了对象的移动，因此成本更高，但是却解决了内存碎片的问题
    * 复制算法 从根集合扫描，并将存活对象复制到一块新的，没有使用过的空间中，这种算法当空间存活的对象比较少时，极为高效，但是带来的成本是需要一块内存交换空间进行对象的移动。也就是s0，s1等空间
* 垃圾收集器，各自的优缺点，重点讲下cms，包括原理，流程，优缺点
    * 串行垃圾收集器：收集时间长，停顿时间久
    * 并发垃圾收集器：碎片空间多
    * CMS：并发标记清除。他的主要步骤有：初始收集，并发标记，重新标记，并发清除（删除），重置
    * G1：主要步骤：初始标记，并发标记，重新标记，复制清除（整理）
    * CMS的缺点是对cpu的要求比较高。G1是将内存化成了多块，所有对内存的大小有很大的要求
    * CMS是清除，所以会存在很多的内存碎片。G1是整理，所以碎片空间较小
    * 吞吐量优先：G1
    * 响应优先：CMS
* osgi是什么？如何实现的？
    * OSGi(Open Service Gateway Initiative)技术是面向Java的动态模型系统
* 做过哪些JVM优化？使用哪些方法？达到什么效果？
* class.forName("java.lang.String")和String.class.getClassLoader.loadClass("java.lang.String")区别？
    * Class.forName是从指定的classloader中装载类,如果没有指定,也就是一个参数的时候,是从装载当前对象实例所在的classloader中装载类
    * ClassLoader的实例调用loadclass方法,是指从当前ClassLoader实例中调用类,而这个实例与装载当前所在类实例的Classloader也许不是同一个
    * 说白了就是他们实现装载的时候，使用的类装载器的指定是不同的
* 怎么知道是哪行代码导致系统CPU高
    * ps -mp PID -o THREAD,tid,time|sort -rn
    * printf "%x\n" TID
    * jstack PID|grep TID -A 80|less

# 分布式消息队列
* 为什么使用消息队列？有什么优点和缺点？
    * 业务解耦/最终一致性/广播/错峰流控
* 如何保证消息队列高可用？保证不被重复消费？
    * 消息队列的高可用，只要保证broker接受消息和确认消息的接口是幂等的，并且consumer的几台机器处理消息是幂等的
    * 关于消息的绝对顺序执行，主动去分配队列，单个消费者
    * 关于消息的重复消费，Consumer保证无状态和幂等性，如果保证不了就用map记录任务状态
* kafka/activemq/rabbitmq/rocketmq各有什么优缺点？
    * 服务端处理同步发送的性能上，Kafka > RocketMQ > RabbitMQ
    * Kafka的队列模式保证了写磁盘的过程是线性IO，所以性能比较高，用于日志系统
    * RocketMQ的消息写入内存后即返回ack，由单独的线程专门做刷盘的操作，所有的消息均是顺序写文件
    * RabbitMQ实现的AMQP协议比较重量级，为了保证消息的可靠性在吞吐量上做了取舍
    * http://dbaplus.cn/news-21-1123-1.html
* 如果让你写一个消息队列，该如何设计？总体思路是怎样的？
    * 设计消息队列的整体思路是先build一个整体的数据流，例如producer发送给broker，broker发送给consumer，consumer回复消费确认，broker删除/备份消息等。
    * 利用RPC将数据流串起来。然后考虑RPC的高可用性，尽量做到无状态，方便水平扩展
    * 之后考虑如何承载消息堆积，然后在合适的时机投递消息，而处理堆积的最佳方式，就是存储，存储的选型需要综合考虑性能/可靠性和开发维护成本等诸多因素
    * 为了实现广播功能，我们必须要维护消费关系，可以利用zk/config server等保存消费关系
    * 在完成了上述几个功能后，消息队列基本就实现了。然后我们可以考虑一些高级特性，如可靠投递，事务特性，性能优化等
    * https://tech.meituan.com/mq-design.html

# 分布式搜索引擎
* es的工作过程实现是怎样的？如何实现分布式？
* es在数据量很大的情况下如何提高查询效率？
    * SSD盘
    * 结合自己的业务实践，使用多个集群，每个集群使用不同的routing，用户是一个routing维度
    * 适当增加分片数量，提升系统的分布水平
* es查询是一个怎样的过程？底层lucence原理是怎样的？倒排序索引是什么？
    * 倒排索引由在文档中出现的唯一的单词列表，以及对于每个单词在文档中的位置组成
* es和mongodb有什么区别？场景又是如何的？
    * MongoDB超过Elasticsearch的地方在于其对于服务器端js脚本的支持、聚合的管道、MapReduce的支持和capped collections，这就保证了MongoDB可以对选定的数据执行任意类型的计算或者转换的终极的灵活性

# 高并发高可用架构设计
* 如何设计一个高可用高并发系统？
    * 无状态，便于扩展，如果有状态则用配置中心实现无状态
    * 拆分，系统／功能／读写／模块
    * 分库分表
    * 消息队列
    * 缓存／降级／限流／可回滚
* 如何限流？工作中怎么实现的？说一下具体实现？
    * 限制总并发数（比如数据库连接池、线程池）
    * 限制瞬时并发数（如nginx的limit_conn模块，用来限制瞬时并发连接数）
    * 限制时间窗口内的平均速率（如Guava的RateLimiter、nginx的limit_req模块，限制每秒的平均速率）
    * 其他还有如限制远程接口调用速率、限制MQ的消费速率
    * 令牌桶算法和漏桶算法
    * 分布式限流使用lua + redis
* 缓存如何使用的？使用不当会造成什么后果？
    * 如果使用不当会导致数据一致性问题、缓存被穿透导致应用雪崩等
* 如何熔断？熔断框架又哪些？具体原理是怎样的？
    * 熔断器Hystrix，Hystrix的Metrics中保存了当前服务的健康状况, Hystrix在1.5版本开始使用RxJava的Observable.window()实现滑动窗口来记录当前时间窗的各种事件
* 如何降级？如何进行系统拆分？如何做数据库拆分？

# 分布式
* 为何需要进行系统拆分？拆分不用dubbo可以实现吗？dubbo和thrift区别？
    * 性能考虑：一个大的系统，往往其中的某个部分，承担了很大的并发压力，或者逻辑运算特别复杂，因此成为系统的性能瓶颈 ，这时就可以考虑将这部分独立出来，从而实现单独部署，再通过负载均衡等手段，来解决性能的问题 
    * 逻辑清晰：根据业务上、流程上的不同环节，将整个系统拆分为不同的子系统，在逻辑上会更加清晰，从而更容易在架构上说清楚，或者进一步做优化
    * 分而治之：减少系统之间的耦合，一个模块出问题，不影响其他模块的运行，同时在开发时可以减少代码冲突
    * 流量限定：将大流量的业务单独剥离出来，提升系统的可控制性
    * 便于管理：随着业务的发展，模块之间的耦合性越来越强 ；开发人员越来越多，相互之间代码版本也难以管理
* 一致性哈希
* RPC原理和设计（通信协议、序列化方式、超时机制等）
* 常见负载均衡策略
* 分布式缓存架构设计
* 分布式事务
* 分布式锁
    * 分布式锁需要满足的条件
    * 互斥性。在任意时刻，只有一个客户端能持有锁。
    * 不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。
    * 容错性。只要大部分的Redis节点正常运行，客户端就可以加锁和解锁。
    * 解铃还须系铃人。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了。
* zk原理
* paxos（这个可能只有在技术专业型很强的职位上会去问）

# JAVA NIO的工作原理，相比JAVA IO有什么优势
* NIO的原理（零拷贝、堆外内存）
* NIO模型，selector职责和实现原理。
* IO包的设计模式（装饰器模式），为什么要这样设计

# 框架
* Spring有哪些机制？AOP底层如何实现的？IOC呢？
    * IOC AOP
    * AOP底层实现：JDK动态代理/CGLIB代理
    * Bean/Context/Core组件
    * [Spring常见问题](http://www.importnew.com/15851.html)
* cglib知道吗？和jdk动态代理区别是什么？手写一个jdk动态代理？
    * 静态代理：事先写好代理对象类，在程序发布前就已经存在了
    * 动态代理：应用程序发布后，通过动态创建代理对象
    * JDK动态代理只能对实现了接口的类生成代理，而不能针对类
    * CGLIB是针对类实现代理，主要是对指定的类生成一个子类，覆盖其中的方法
    * 因为是继承，所以该类或方法最好不要声明成final，final可以阻止继承和多态
    * Java动态代理是写一个类实现InvocationHandler接口，重写Invoke方法，在Invoke方法可以进行增强处理的逻辑的编写
* 说一下dubbo的实现过程？如果注册中心挂了，可以继续通信吗？
    * 注册中心挂了可以继续通信的，因为消费者本地有一个生产者的列表，但无法从注册中心去同步最新的服务列表，短期的注册中心挂掉是不要紧的，但一定要尽快修复
* zk原理？zk应用场景？paxos算法了解吗？说一下原理和实现
    * Zookeeper 的核心是广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做Zab协议
* dubbo支持哪些序列化协议？hessian？hessian数据结构是怎样的？PB知道吗？为啥PB效率更高？
    * dubbo序列化
    * hessian序列化
    * json序列化
    * Kryo
    * PB序列化&反序列化简单只需要简单的数学运算 = 位移等等
    * PB数据压缩效果好，采用了独特的编码方式，如Varint、Zigzag编码方式等等，采用T-L-V的数据存储方式减少了分隔符的使用
* duubo负载均衡策略和高可用策略有哪些？动态代理策略呢？
    * 随机／轮询／最少使用／一致性hash
* MyBatis机制

# 项目
* 日常工作内容是什么
* 最有技术难度的地方是什么
* 如何应对项目延期
* 项目中遇到的困难（提前想好，并且把实现或者优化方法说清楚）

# MySQL
* MySQLQL使用什么关键字来分析SQL的性能
    * type 类型的性能比较 ALL < index < range ~ index_merge < ref < eq_ref < const < system
* 数据库性能优化（慢sql、索引优化、大事务、内核参数调优），工作中碰到过什么诡异场景
* 建立索引有什么注意点
    * 区分度大的字段
    * 索引不宜过多
    * 合理使用复合索引
* 什么是覆盖索引
    * 指一个查询语句的执行只需要从辅助索引中就可以得到查询记录，而不需要查询聚集索引中的记录。也可以称之为实现了索引覆盖。
* 什么情况下需要建立复合索引
    * select返回列较少或列宽较小的时候，我们可以通过建立复合索引避免回表
* 索引原理是什么，底层用什么数据结构
    * B+树
* 数据库是如何做容灾的
    * HA方案 主从 MHA MMM
* 如何做到动态增加业务字段，而代码无需改动
* MySQL死锁形成原因，如何避免死锁
    * 死锁一般是事务相互等待对方资源，最后形成环路造成的
    * 以固定的顺序访问表和行。
    * 大事务拆小。大事务更倾向于死锁，如果业务允许，将大事务拆小。
    * 在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁概率。
    * 降低隔离级别。如果业务允许，将隔离级别调低也是较好的选择，比如将隔离级别从RR调整为RC，可以避免掉很多因为gap锁造成的死锁。
    * 为表添加合理的索引。可以看到如果不走索引将会为表的每一行记录添加上锁，死锁的概率大大增大。
* 行锁和表锁的区别，innodb引擎用的是哪种锁
* 为什么推荐使用自增id做为主键
    * 索引在物理上按照主键大小顺序存储，使用其他列或者组合无法保证顺序插入
    * InnoDB表的数据写入顺序能和B+树索引的叶子节点顺序一致的话，这时候存取效率是最高的
* 批量插入数据的时候，怎么优化
    * 一条SQL语句插入多条数据
    * 在事务中进行插入处理
    * 数据有序插入
* 你参与的项目，有做分库处理吗，路由到分库的规则是什么
    * userid分库分表
* 主从同步原理，如何降低主从同步延迟
    * Master主库将数据变更DataChanges记录binlog日志中。
    * Slave起一个I/O线程连接到Master，dump读取Master的binlog日志并写入到Slave的中继日志Relaylog中
    * Slave中的SQL线程读取中继日志Relaylog进行SQL回放执行操作，完成主从复制，保证主从最终一致性。
* 使用MySQL索引都有哪些原则？索引是什么数据结构？B+tree和B tree什么区别？
    * 最左前缀匹配
    * 唯一索引
    * 联合索引
    * B+tree是变种，每个节点的指针上限为2d而不是2d+1，内节点不存储data，只存储key，叶子节点不存储指针
    * B+tree的结构设计具体原因与外存储器原理及计算机存取原理有关，局部性原理与磁盘预读
* MySQL存储引擎有哪些？有什么区别？
    * MyISAM 支持全文索引 索引和数据分开 表锁
    * InnoDB 支持事务 索引即数据 行锁
    * MEMORY 使用Hash索引，全内存
* MySQL双主（主主）架构方案思路是:
    * 两台mysql都可读写，互为主备，默认只使用一台（masterA）负责数据的写入，另一台（masterB）备用；
    * masterA是masterB的主库，masterB又是masterA的主库，它们互为主从；
    * 两台主库之间做高可用,可以采用keepalived等方案（使用VIP对外提供服务）；
    * 所有提供服务的从服务器与masterB进行主从同步（双主多从）;
    * 建议采用高可用策略的时候，masterA或masterB均不因宕机恢复后而抢占VIP（非抢占模式）；
* 半同步复制
    * 介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到并写到relay log中才返回给客户端。相对于异步复制，半同步复制提高了数据的安全性，同时它也造成了一定程度的延迟，这个延迟最少是一个TCP/IP往返的时间。所以，半同步复制最好在低延时的网络中使用。
* 设计高并发系统数据库层面该怎么设计？数据库锁有哪些类型？如何实现？
    * 行锁
    * 页锁
    * 表锁
    * MyISAM中是不会产生死锁的，因为MyISAM总是一次性获得所需的全部锁，要么全部满足，要么全部等待
    * 在MySQL中，行级锁并不是直接锁记录，而是锁索引
* 数据库事务有哪些？
    * ACID 原子／一致性／隔离性／持久性
    * 隔离级别 未提交读 已提交读 可重复读 可序列化
* 为什么MyISAM读更快“快”
    * INNODB在做SELECT的时候，要维护的东西比MYISAM引擎多很多:
    * 数据块，InnoDB要缓存，MyISAM只缓存索引块，  这中间还有换进换出的减少
    * InnoDB寻址要映射到块，再到行，MYISAM记录的直接是文件的OFFSET，定位比INNODB要快
    * InnoDB还需要维护MVCC (Multi-Version Concurrency Control)多版本并发控制，虽然你的场景没有，但他还是需要去检查和维护
* 关于为什么定义不使用Null的原因
    * 浪费存储空间，因为InnoDB需要有额外一个字节存储
    * 表内默认值Null过多会影响优化器选择执行计划
    * 避免使用NULL字段 NULL字段很难查询优化 NULL字段的索引需要额外空间 NULL字段的复合索引无效

# 缓存
* redis和memcached区别？为什么单线程的redis比多线程的memcached效率更高？
    * memcached是多线程模型，能完全使用到多核，底层依赖的是通用的libevent库。为了保证线程安全，内部有大量的锁的代码
    * memcached指令执行次数多，线程切换次数多耗时也多，需要获取锁、释放锁的次数更多，如果锁冲突的机率高，线程等待时间变多，等于变相减小多线程处理能力
* 系统有用本地缓存吗，是如何做命中率的统计的
* 选择堆外缓存和堆内缓存的依据是什么
* 从堆外缓存获取数据需要反序列化，有办法避免吗
* Redis常用数据结构
    * String Hash List Set SortedSet
* Redis持久化rdb和aof原理
* 持久化
    * 同时开启两种持久化方式，当redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。
    * 虽然SAVE会一直阻塞Redis直到快照生成完毕，但是因为它不需要创建子进程，所以不会像BGSAVE一样因为创建子进程而导致Redis停顿
* Redis持久化磁盘IO方式内存没有满时就可能崩溃
    * 持久化使用了Buffer IO造成的，所谓Buffer IO是指Redis对持久化文件的写入和读取操作都会使用物理内存的Page Cache
    * 大多数数据库系统会使用Direct IO来绕过这层Page Cache并自行维护一个数据的Cache
    * 当持久化文件过大(尤其是快照文件)，并对其进行读写时，磁盘文件中的数据都会被加载到物理内存中作为操作系统对该文件的一层Cache
    * 这层Cache的数据与Redis内存中管理的数据实际是重复存储的，虽然内核在物理内存紧张时会做Page Cache的剔除工作
    * 但内核很可能认为某块Page Cache更重要，而让你的进程开始Swap
    * 这时你的系统就会开始出现不稳定或者崩溃了。我们的经验是当你的Redis物理内存使用超过内存总容量的3/5时就会开始比较危险了
* Redis主从同步原理
     * slave向master发送sync指令，master接收到时调用bgsave指令fork一个子进程进行持久化工作，该期间master的写指令都缓存在内存中
     * bgsave指令完成后master会将rdb文件发送给slave，slave接收到后将其存在磁盘上，然后读入内存，这个动作完成后master会将这段时间缓存的写指令再以redis协议的格式发送给slave
     * 2.8版本引入增量同步机制
     * 集群方案：Redis官方集群方案RedisCluster 服务端sharding RedisProxy（Codis&Twemproxy）
* redis过期策略有哪些？LRU？代码实现？
    * 被动删除 get/del时判断是否过期
    * 主动删除 定时清除
    * 超过内存触发主动删除
* 如何实现Redis高可用
    * 哨兵
    * Twemproxy&Codis
* Redis Cluster
    * Redis 集群不像单机Redis 那样支持多数据库功能， 集群只使用默认的 0 号数据库， 并且不能使用 SELECT 命令。
    * 是无中心的架构，判断节点失败是通过仲裁的方式来进行（gossip和raft），也就是大部分节点认为一个节点挂掉了，就会做fail判定
    * 节点之间使用Gossip 协议 来进行以下工作
* 事务
    * MULTI用来组装一个事务
    * EC用来执行一个事
    * DISCARD用来取消一个事务
    * WATCH用来监视一些key，一旦这些key在事务执行之前被改变，则取消事务的执行

# 网络协议
* TCP/IP 协议是怎样的？
    * 是一系列网络协议的总和，是构成网络通信的核心骨架，它定义了电子设备如何连入因特网，以及数据如何在它们之间进行传输
    * TCP/IP协议采用4层结构，分别是应用层、传输层、网络层和链路层
* http工作流程？http1.0 1.1 2.0具体有哪些区别?
    * 域名解析 -> tcp三次握手建立链接 -> 响应http请求 报文（状态码/报头/正文）->  解析报文内容
    * 1.0 链接无法复用，即不支持持久链接；线头阻塞（Head of Line (HOL) Blocking）
    * 1.1 支持持久链接（在request和response中的header中的connection是close或者Keep-Alive进行控制）;支持http管道
    * 2.0把解决性能问题的方案内置在了传输层，通过多路复用来减少延迟，通过压缩 HTTP首部降低开销，同时增加请求优先级和服务器端推送的功能
* TCP三次次握手和四次挥手？画一下流程图
    * 三次握手建立链接：SYN=i -> ACK=i+1 SYN=j -> ACK=j+1
    * 四次挥手断开链接：FIN=i -> ACK=i+1, FIN=j -> ACK=j+1
    * 关闭连接时，当收到对方的FIN，它仅仅表示对方没有数据发送给你了，但未必你所有的数据都全部发送给对方了，所以你可能未必会马上会关闭SOCKET，即你可能还需要发送一些数据给对方之后，再发送FIN报文给对方来表示你同意现在可以关闭连接了，所以它这里的ACK报文和FIN报文多数情况下都是分开发送的
* 画一下https的工作流程？具体如何实现的？如何防止被抓包？
    * client发起请求 -> server返回证书（即公钥）-> client校验证书合法性 -> client用证书加密一个随机值发送给server -> server用对应的密钥解析得到这个随机值并用这个随机值对称加密要传输内容 -> client还原加密的内容
* 如何用JAVA代码解析一个HTTP请求，描述一下实现的思路
* DDoS原理
    * SYN-Flood泛洪攻击是当前网络上最为常见的DDoS攻击，攻击者首先伪造地址对服务器发起SYN请求

# 操作系统
* 常用命令grep find awk

# 安全
* CSRF
    * 跨站请求伪造 攻击者盗用了你的身份，以你的名义发送恶意请求
* XSS
    * 注入攻击
* 常见加密算法
    * DES 是一种对称加密算法，所谓对称加密算法即：加密和解密使用相同密钥的算法
    * AES 替代原先的DES
    * RSA 目前最有影响力的公钥加密算法
    * Base64 是网络上最常见的用于传输8bit字节代码的编码方式之一
    * MD5 消息摘要算法
    * SHA1 和MD5一样流行的消息摘要算法

# 算法
* 给定一组整数，要求在其中找出所有3个字之和为k的组合。类似于leetcode上这道题：https://leetcode.com/problems/3sum/description/
* 一个单向链表，如何判断该链表是否有环，并且输出环的入口点
    * 方法1：双指针，每次迭代时，指针1走一步，指针2走两步，指针重合时表示有环，此时再调整快指针从头开始走并且每次走1步，慢指针保持原速走，再次相交时即为入口点
    * 方法2：将每次走过的节点保存到hash表中，如果节点在hash表中，则表示存在环
* 两个单向链表，如何判断这两个链表是否有交叉
    * 首先根据链表长度对齐，分别向移动，第一次节点相等时即为交叉点
* 求链表倒数第k个节点
    * 快指针先走k步，然后慢指针开始走，两指针一起走，当快指针到达尾节点时慢指针节点即为所求节点
* 3sum
    * 数组排序（从小到大），然后从数组两端向中间移动，和大于目标则右端指针减一，小于目标左端指针加一
* 删除链表节点O(1)
    * 可以从给定要删除的结点得到它的下一个结点。
    * 我们需要需要把给定的结点的下一个结点的数据拷贝到给定的结点中，然后删除该节点的下一个节点。此时，时间平均复杂度为O(1)
* 查找字符串
* 最长公共子串
* 快速排序

# 参考
* http://blog.jobbole.com/99911/
* http://blog.csdn.net/tzs_1041218129/article/details/52355867
* http://blog.csdn.net/tzs_1041218129/article/details/52415971
